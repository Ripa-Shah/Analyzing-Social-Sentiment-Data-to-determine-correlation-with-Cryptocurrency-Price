{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a48501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\source\\repos\\Ripa-Shah\\Sentiment-Analysis\\Analyzing-Social-Sentiment-Data-to-determine-correlation-with-Cryptocurrency-Price\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd C:\\Users\\yashs\\source\\repos\\Ripa-Shah\\Sentiment-Analysis\\Analyzing-Social-Sentiment-Data-to-determine-correlation-with-Cryptocurrency-Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2449d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Starting Reddit post & comment sentiment streaming...\n",
      "\n",
      "--- ‚è≥ Running Historical Fetch (Every 14400s) ---\n",
      "--- Checking Top posts for: DAY ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_54252\\4101367168.py:111: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  dt_utc = datetime.utcfromtimestamp(post_timestamp)\n",
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_54252\\4101367168.py:147: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  comment_date = datetime.utcfromtimestamp(comment.created_utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_54252\\4101367168.py:199: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  print(f\"‚úÖ Historical Post ({time_filter}): {datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S')} | {records[0][4]} | Sentiment: {records[0][-1]:+.3f}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Historical Post (day): 2025-11-17 06:29:21 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (day): 2025-11-17 20:28:10 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (day): 2025-11-17 06:19:50 | BTC | Sentiment: -0.572\n",
      "‚úÖ Historical Post (day): 2025-11-17 13:40:21 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (day): 2025-11-17 19:12:11 | BTC | Sentiment: -0.998\n",
      "‚úÖ Historical Post (day): 2025-11-17 03:22:20 | ADA | Sentiment: -0.318\n",
      "‚úÖ Historical Post (day): 2025-11-17 15:26:48 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (day): 2025-11-17 14:23:20 | BTC | Sentiment: -0.951\n",
      "‚úÖ Historical Post (day): 2025-11-17 13:46:25 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (day): 2025-11-17 02:46:00 | BTC | Sentiment: +0.869\n",
      "‚úÖ Historical Post (day): 2025-11-17 20:22:37 | BTC | Sentiment: +0.831\n",
      "‚úÖ Historical Post (day): 2025-11-17 01:01:14 | ETH | Sentiment: +0.954\n",
      "‚úÖ Historical Post (day): 2025-11-17 08:26:47 | BTC | Sentiment: -0.670\n",
      "‚úÖ Historical Post (day): 2025-11-17 16:24:09 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (day): 2025-11-17 18:52:21 | BTC | Sentiment: +0.361\n",
      "‚úÖ Historical Post (day): 2025-11-17 18:36:08 | ADA | Sentiment: +0.000\n",
      "‚úÖ Historical Post (day): 2025-11-17 21:49:49 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (day): 2025-11-17 17:09:58 | BTC | Sentiment: -0.511\n",
      "‚úÖ Historical Post (day): 2025-11-17 10:45:09 | ADA | Sentiment: -0.402\n",
      "‚úÖ Historical Post (day): 2025-11-17 09:57:02 | BTC | Sentiment: -0.103\n",
      "‚úÖ Historical Post (day): 2025-11-17 08:16:11 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (day): 2025-11-17 03:47:44 | BTC | Sentiment: -0.599\n",
      "‚úÖ Historical Post (day): 2025-11-17 21:07:12 | ETH | Sentiment: -0.496\n",
      "‚úÖ Historical Post (day): 2025-11-17 19:37:22 | BTC | Sentiment: -0.625\n",
      "‚úÖ Historical Post (day): 2025-11-17 14:25:28 | BTC | Sentiment: -0.677\n",
      "‚úÖ Historical Post (day): 2025-11-17 20:23:33 | ETH | Sentiment: +0.987\n",
      "‚úÖ Historical Post (day): 2025-11-17 20:35:15 | SOL | Sentiment: +0.533\n",
      "‚úÖ Historical Post (day): 2025-11-17 18:23:44 | ETH | Sentiment: +0.642\n",
      "‚úÖ Historical Post (day): 2025-11-17 14:28:33 | ETH | Sentiment: +0.858\n",
      "‚úÖ Historical Post (day): 2025-11-17 17:11:58 | BTC | Sentiment: -0.309\n",
      "--- Checking Top posts for: WEEK ---\n",
      "‚úÖ Historical Post (week): 2025-11-14 12:15:45 | BTC | Sentiment: -0.421\n",
      "‚úÖ Historical Post (week): 2025-11-13 18:48:54 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-11 19:21:29 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-15 04:51:36 | BTC | Sentiment: -0.296\n",
      "‚úÖ Historical Post (week): 2025-11-11 18:46:04 | BTC | Sentiment: -0.991\n",
      "‚úÖ Historical Post (week): 2025-11-11 19:28:23 | BTC | Sentiment: -0.340\n",
      "‚úÖ Historical Post (week): 2025-11-16 19:54:31 | ETH | Sentiment: -0.866\n",
      "‚úÖ Historical Post (week): 2025-11-14 20:08:29 | BTC | Sentiment: -0.670\n",
      "‚úÖ Historical Post (week): 2025-11-16 06:12:57 | BTC | Sentiment: -0.273\n",
      "‚úÖ Historical Post (week): 2025-11-11 15:40:20 | BTC | Sentiment: +0.872\n",
      "‚úÖ Historical Post (week): 2025-11-16 21:34:43 | ETH | Sentiment: -0.606\n",
      "‚úÖ Historical Post (week): 2025-11-16 23:11:03 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-14 17:06:34 | BTC | Sentiment: -0.421\n",
      "‚úÖ Historical Post (week): 2025-11-12 07:08:34 | BTC | Sentiment: -0.318\n",
      "‚úÖ Historical Post (week): 2025-11-13 15:14:36 | BTC | Sentiment: +0.219\n",
      "‚úÖ Historical Post (week): 2025-11-12 15:59:05 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-13 18:57:30 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-15 07:33:39 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-16 15:50:49 | BTC | Sentiment: -0.318\n",
      "‚úÖ Historical Post (week): 2025-11-12 21:44:28 | BTC | Sentiment: -0.052\n",
      "‚úÖ Historical Post (week): 2025-11-12 08:20:15 | ETH | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-15 17:58:58 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-13 17:57:07 | BTC | Sentiment: -0.296\n",
      "‚úÖ Historical Post (week): 2025-11-13 19:27:43 | BTC | Sentiment: -0.712\n",
      "‚úÖ Historical Post (week): 2025-11-13 16:20:23 | BTC | Sentiment: +0.542\n",
      "‚úÖ Historical Post (week): 2025-11-11 16:20:59 | BTC | Sentiment: -0.477\n",
      "‚úÖ Historical Post (week): 2025-11-15 02:50:11 | ETH | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-13 14:21:36 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-15 07:45:47 | BTC | Sentiment: -0.186\n",
      "‚úÖ Historical Post (week): 2025-11-13 22:04:01 | BTC | Sentiment: +0.956\n",
      "‚úÖ Historical Post (week): 2025-11-14 10:31:10 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-14 12:55:28 | ETH | Sentiment: +0.402\n",
      "‚úÖ Historical Post (week): 2025-11-13 10:00:52 | ETH | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-16 16:51:59 | BTC | Sentiment: -0.850\n",
      "‚úÖ Historical Post (week): 2025-11-15 17:00:00 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-13 19:20:47 | BTC | Sentiment: +0.202\n",
      "‚úÖ Historical Post (week): 2025-11-12 17:38:58 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-12 19:16:17 | ETH | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-13 18:46:46 | BTC | Sentiment: -0.541\n",
      "‚úÖ Historical Post (week): 2025-11-11 05:29:01 | BTC | Sentiment: -0.026\n",
      "‚úÖ Historical Post (week): 2025-11-12 08:48:46 | BTC | Sentiment: -0.318\n",
      "‚úÖ Historical Post (week): 2025-11-15 10:47:26 | BTC | Sentiment: -0.681\n",
      "‚úÖ Historical Post (week): 2025-11-14 16:31:37 | BTC | Sentiment: +0.984\n",
      "‚úÖ Historical Post (week): 2025-11-15 19:52:48 | ETH | Sentiment: +0.202\n",
      "‚úÖ Historical Post (week): 2025-11-12 20:54:36 | BTC | Sentiment: -0.128\n",
      "‚úÖ Historical Post (week): 2025-11-16 19:17:32 | BTC | Sentiment: +0.749\n",
      "‚úÖ Historical Post (week): 2025-11-12 01:00:39 | ETH | Sentiment: +0.954\n",
      "‚úÖ Historical Post (week): 2025-11-11 16:58:43 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-12 07:48:38 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-11 11:55:09 | ETH | Sentiment: +0.989\n",
      "‚úÖ Historical Post (week): 2025-11-11 07:31:54 | BTC | Sentiment: +0.421\n",
      "‚úÖ Historical Post (week): 2025-11-11 01:00:50 | ETH | Sentiment: +0.954\n",
      "‚úÖ Historical Post (week): 2025-11-16 07:20:12 | BTC | Sentiment: +0.978\n",
      "‚úÖ Historical Post (week): 2025-11-16 01:00:44 | ETH | Sentiment: +0.954\n",
      "‚úÖ Historical Post (week): 2025-11-12 14:44:20 | BTC | Sentiment: +0.097\n",
      "‚úÖ Historical Post (week): 2025-11-13 01:00:55 | ETH | Sentiment: +0.954\n",
      "‚úÖ Historical Post (week): 2025-11-14 14:19:40 | BTC | Sentiment: +0.440\n",
      "‚úÖ Historical Post (week): 2025-11-14 01:00:47 | ETH | Sentiment: +0.954\n",
      "‚úÖ Historical Post (week): 2025-11-11 19:12:56 | ETH | Sentiment: +0.947\n",
      "‚úÖ Historical Post (week): 2025-11-16 23:07:16 | BTC | Sentiment: -0.272\n",
      "‚úÖ Historical Post (week): 2025-11-16 10:36:02 | BTC | Sentiment: +0.534\n",
      "‚úÖ Historical Post (week): 2025-11-12 19:19:53 | BTC | Sentiment: -0.840\n",
      "‚úÖ Historical Post (week): 2025-11-11 20:59:06 | ADA | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-16 10:46:20 | BTC | Sentiment: -0.178\n",
      "‚úÖ Historical Post (week): 2025-11-16 05:21:56 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-15 01:00:46 | ETH | Sentiment: +0.954\n",
      "‚úÖ Historical Post (week): 2025-11-11 15:04:40 | BTC | Sentiment: +0.854\n",
      "‚úÖ Historical Post (week): 2025-11-14 16:29:24 | BTC | Sentiment: +0.975\n",
      "‚úÖ Historical Post (week): 2025-11-11 01:25:19 | ETH | Sentiment: +1.000\n",
      "‚úÖ Historical Post (week): 2025-11-14 20:02:44 | ETH | Sentiment: +0.788\n",
      "‚úÖ Historical Post (week): 2025-11-13 00:24:44 | ETH | Sentiment: +0.765\n",
      "‚úÖ Historical Post (week): 2025-11-11 18:21:23 | ETH | Sentiment: +0.318\n",
      "‚úÖ Historical Post (week): 2025-11-11 21:34:47 | BTC | Sentiment: -0.727\n",
      "‚úÖ Historical Post (week): 2025-11-12 18:31:54 | ETH | Sentiment: +0.968\n",
      "‚úÖ Historical Post (week): 2025-11-11 08:09:06 | BTC | Sentiment: +0.599\n",
      "‚úÖ Historical Post (week): 2025-11-12 19:14:22 | BTC | Sentiment: -0.446\n",
      "‚úÖ Historical Post (week): 2025-11-14 07:53:12 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-14 06:31:54 | ETH | Sentiment: -0.077\n",
      "‚úÖ Historical Post (week): 2025-11-12 20:48:05 | SOL | Sentiment: -0.178\n",
      "‚úÖ Historical Post (week): 2025-11-15 10:31:26 | ETH | Sentiment: +0.743\n",
      "‚úÖ Historical Post (week): 2025-11-11 10:04:11 | ETH | Sentiment: +0.833\n",
      "‚úÖ Historical Post (week): 2025-11-13 20:48:25 | ETH | Sentiment: -0.572\n",
      "‚úÖ Historical Post (week): 2025-11-12 11:53:21 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-12 20:37:36 | ETH | Sentiment: +0.026\n",
      "‚úÖ Historical Post (week): 2025-11-11 08:21:14 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (week): 2025-11-11 04:52:32 | ETH | Sentiment: +0.998\n",
      "‚úÖ Historical Post (week): 2025-11-14 21:43:38 | ETH | Sentiment: +0.000\n",
      "--- Checking Top posts for: MONTH ---\n",
      "‚úÖ Historical Post (month): 2025-10-31 21:39:48 | BTC | Sentiment: +0.996\n",
      "‚úÖ Historical Post (month): 2025-10-28 16:31:02 | BTC | Sentiment: +0.361\n",
      "‚úÖ Historical Post (month): 2025-11-07 17:39:54 | BTC | Sentiment: +0.532\n",
      "‚úÖ Historical Post (month): 2025-11-07 11:14:05 | ETH | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-10-25 18:16:55 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-11-06 08:17:16 | BTC | Sentiment: -0.542\n",
      "‚úÖ Historical Post (month): 2025-10-26 15:24:54 | BTC | Sentiment: +0.226\n",
      "‚úÖ Historical Post (month): 2025-10-19 18:54:34 | SOL | Sentiment: -0.988\n",
      "‚úÖ Historical Post (month): 2025-10-21 20:50:07 | BTC | Sentiment: -0.402\n",
      "‚úÖ Historical Post (month): 2025-10-28 00:41:42 | BTC | Sentiment: +0.202\n",
      "‚úÖ Historical Post (month): 2025-10-19 17:38:37 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-10-29 11:28:08 | SOL | Sentiment: -0.948\n",
      "‚úÖ Historical Post (month): 2025-11-04 21:19:34 | BTC | Sentiment: -0.813\n",
      "‚úÖ Historical Post (month): 2025-11-04 09:44:13 | BTC | Sentiment: +0.812\n",
      "‚úÖ Historical Post (month): 2025-11-07 22:12:55 | BTC | Sentiment: +0.331\n",
      "‚úÖ Historical Post (month): 2025-11-05 17:46:52 | BTC | Sentiment: -0.103\n",
      "‚úÖ Historical Post (month): 2025-10-30 15:05:36 | BTC | Sentiment: -0.296\n",
      "‚úÖ Historical Post (month): 2025-10-23 13:15:01 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-11-05 01:04:34 | BTC | Sentiment: +0.537\n",
      "‚úÖ Historical Post (month): 2025-11-01 19:27:22 | BTC | Sentiment: -0.660\n",
      "‚úÖ Historical Post (month): 2025-11-10 13:32:41 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-10-31 08:56:42 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-10-27 20:00:00 | BTC | Sentiment: +0.226\n",
      "‚úÖ Historical Post (month): 2025-11-04 08:02:34 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-10-21 22:08:36 | BTC | Sentiment: +0.103\n",
      "‚úÖ Historical Post (month): 2025-11-04 03:09:22 | BTC | Sentiment: -0.402\n",
      "‚úÖ Historical Post (month): 2025-11-04 19:05:20 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-11-01 19:10:04 | ETH | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-10-24 07:56:34 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-11-04 16:32:04 | BTC | Sentiment: -0.855\n",
      "‚úÖ Historical Post (month): 2025-10-26 13:48:45 | ETH | Sentiment: +0.866\n",
      "‚úÖ Historical Post (month): 2025-11-07 17:51:16 | BTC | Sentiment: -0.477\n",
      "‚úÖ Historical Post (month): 2025-10-21 05:21:18 | BTC | Sentiment: -0.527\n",
      "‚úÖ Historical Post (month): 2025-10-27 13:31:27 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-10-20 17:02:23 | BTC | Sentiment: +0.226\n",
      "‚úÖ Historical Post (month): 2025-11-06 15:29:05 | BTC | Sentiment: +0.202\n",
      "‚úÖ Historical Post (month): 2025-10-20 06:52:50 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-11-03 16:48:08 | BTC | Sentiment: +0.202\n",
      "‚úÖ Historical Post (month): 2025-10-26 21:07:30 | ETH | Sentiment: +0.972\n",
      "‚úÖ Historical Post (month): 2025-10-19 11:31:19 | BTC | Sentiment: -0.988\n",
      "‚úÖ Historical Post (month): 2025-10-19 02:46:19 | ETH | Sentiment: +0.361\n",
      "‚úÖ Historical Post (month): 2025-11-04 17:40:01 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-11-06 13:55:35 | BTC | Sentiment: -0.612\n",
      "‚úÖ Historical Post (month): 2025-11-10 15:36:32 | BTC | Sentiment: +0.226\n",
      "‚úÖ Historical Post (month): 2025-10-30 15:17:38 | BTC | Sentiment: -0.494\n",
      "‚úÖ Historical Post (month): 2025-11-08 14:41:18 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-11-01 08:01:54 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-10-28 16:52:30 | BTC | Sentiment: +0.964\n",
      "‚úÖ Historical Post (month): 2025-11-09 15:19:49 | ETH | Sentiment: +0.401\n",
      "‚úÖ Historical Post (month): 2025-10-30 09:28:53 | BTC | Sentiment: -0.406\n",
      "‚úÖ Historical Post (month): 2025-11-02 17:46:20 | BTC | Sentiment: +0.273\n",
      "‚úÖ Historical Post (month): 2025-11-05 09:07:50 | BTC | Sentiment: -0.710\n",
      "‚úÖ Historical Post (month): 2025-11-02 00:01:48 | ETH | Sentiment: +0.440\n",
      "‚úÖ Historical Post (month): 2025-10-26 11:33:03 | ETH | Sentiment: +0.441\n",
      "‚úÖ Historical Post (month): 2025-10-29 20:31:04 | BTC | Sentiment: -0.477\n",
      "‚úÖ Historical Post (month): 2025-10-29 18:49:39 | BTC | Sentiment: +0.382\n",
      "‚úÖ Historical Post (month): 2025-10-22 03:04:15 | BTC | Sentiment: -0.542\n",
      "‚úÖ Historical Post (month): 2025-11-08 21:51:22 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-11-03 17:33:03 | BTC | Sentiment: -0.986\n",
      "‚úÖ Historical Post (month): 2025-10-30 12:17:15 | BTC | Sentiment: -0.527\n",
      "‚úÖ Historical Post (month): 2025-10-31 16:08:22 | ETH | Sentiment: +0.973\n",
      "‚úÖ Historical Post (month): 2025-11-04 20:42:29 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-10-30 14:50:52 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-11-10 04:45:59 | BTC | Sentiment: +0.153\n",
      "‚úÖ Historical Post (month): 2025-10-25 03:48:24 | BTC | Sentiment: -0.700\n",
      "‚úÖ Historical Post (month): 2025-10-28 14:54:59 | SOL | Sentiment: +0.996\n",
      "‚úÖ Historical Post (month): 2025-10-19 16:25:20 | BTC | Sentiment: +0.226\n",
      "‚úÖ Historical Post (month): 2025-10-20 22:22:54 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-10-26 21:41:47 | ETH | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-10-25 16:11:32 | BTC | Sentiment: +0.572\n",
      "‚úÖ Historical Post (month): 2025-10-24 05:50:48 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-10-27 20:22:56 | BTC | Sentiment: +0.527\n",
      "‚úÖ Historical Post (month): 2025-10-24 17:53:02 | BTC | Sentiment: +0.440\n",
      "‚úÖ Historical Post (month): 2025-10-19 10:00:33 | ETH | Sentiment: +0.103\n",
      "‚úÖ Historical Post (month): 2025-11-03 21:20:36 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-10-19 00:35:22 | ADA | Sentiment: -0.954\n",
      "‚úÖ Historical Post (month): 2025-11-10 20:37:29 | BTC | Sentiment: -0.516\n",
      "‚úÖ Historical Post (month): 2025-10-26 13:36:02 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-10-25 01:47:13 | ETH | Sentiment: +0.981\n",
      "‚úÖ Historical Post (month): 2025-11-04 07:57:52 | ETH | Sentiment: +0.000\n",
      "‚úÖ Historical Post (month): 2025-11-07 09:59:44 | BTC | Sentiment: +0.572\n",
      "‚úÖ Historical Post (month): 2025-10-30 21:35:30 | BTC | Sentiment: +0.440\n",
      "--- Checking Top posts for: YEAR ---\n",
      "‚úÖ Historical Post (year): 2025-07-04 08:00:56 | BTC | Sentiment: -0.077\n",
      "‚úÖ Historical Post (year): 2025-02-15 15:13:54 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-04-03 12:46:10 | ETH | Sentiment: +0.421\n",
      "‚úÖ Historical Post (year): 2025-10-14 19:29:50 | BTC | Sentiment: -0.494\n",
      "‚úÖ Historical Post (year): 2025-02-06 17:39:45 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-02-07 23:17:28 | BTC | Sentiment: -0.992\n",
      "‚úÖ Historical Post (year): 2025-01-07 05:08:47 | BTC | Sentiment: +0.271\n",
      "‚úÖ Historical Post (year): 2025-02-07 19:00:56 | BTC | Sentiment: +0.026\n",
      "‚úÖ Historical Post (year): 2025-09-14 13:52:36 | BTC | Sentiment: -0.226\n",
      "‚úÖ Historical Post (year): 2024-12-05 02:39:33 | BTC | Sentiment: +0.318\n",
      "‚úÖ Historical Post (year): 2024-12-11 12:32:03 | BTC | Sentiment: +0.226\n",
      "‚úÖ Historical Post (year): 2025-01-27 17:04:02 | SOL | Sentiment: +0.128\n",
      "‚úÖ Historical Post (year): 2025-09-19 13:42:03 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-01-18 20:35:05 | SOL | Sentiment: +0.700\n",
      "‚úÖ Historical Post (year): 2025-03-07 01:29:18 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-03-10 18:37:57 | SOL | Sentiment: -0.360\n",
      "‚úÖ Historical Post (year): 2025-05-22 03:50:41 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2024-12-22 16:30:21 | BTC | Sentiment: -0.273\n",
      "‚úÖ Historical Post (year): 2025-08-21 17:10:25 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-02-20 15:08:27 | BTC | Sentiment: +0.440\n",
      "‚úÖ Historical Post (year): 2025-05-05 02:45:11 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-01-30 21:08:07 | ETH | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2024-12-14 15:13:08 | ETH | Sentiment: +0.625\n",
      "‚úÖ Historical Post (year): 2025-10-11 15:43:18 | SOL | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-09-03 16:55:48 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-03-23 13:15:03 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-03-03 11:39:41 | BTC | Sentiment: +0.691\n",
      "‚úÖ Historical Post (year): 2025-01-28 19:58:31 | BTC | Sentiment: -0.361\n",
      "‚úÖ Historical Post (year): 2025-01-24 14:50:41 | BTC | Sentiment: -0.638\n",
      "‚úÖ Historical Post (year): 2025-07-17 17:52:50 | ETH | Sentiment: +0.250\n",
      "‚úÖ Historical Post (year): 2025-01-25 14:57:23 | ETH | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-10-02 19:24:34 | SOL | Sentiment: +0.202\n",
      "‚úÖ Historical Post (year): 2025-01-20 00:57:26 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-03-04 11:06:53 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-01-27 00:43:13 | ETH | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2024-12-05 02:53:09 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-05-29 19:56:08 | BTC | Sentiment: +0.649\n",
      "‚úÖ Historical Post (year): 2025-05-11 09:09:36 | BTC | Sentiment: +0.361\n",
      "‚úÖ Historical Post (year): 2024-12-05 19:57:18 | BTC | Sentiment: -0.103\n",
      "‚úÖ Historical Post (year): 2025-05-30 08:08:34 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-03-07 15:48:45 | BTC | Sentiment: -0.784\n",
      "‚úÖ Historical Post (year): 2025-01-21 20:02:03 | BTC | Sentiment: -0.802\n",
      "‚úÖ Historical Post (year): 2025-03-09 00:58:34 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-02-21 07:02:39 | BTC | Sentiment: -0.440\n",
      "‚úÖ Historical Post (year): 2025-03-21 20:07:38 | ETH | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-03-11 21:12:18 | BTC | Sentiment: -0.440\n",
      "‚úÖ Historical Post (year): 2025-01-02 04:52:09 | BTC | Sentiment: +0.927\n",
      "‚úÖ Historical Post (year): 2024-12-17 18:33:22 | BTC | Sentiment: +0.527\n",
      "‚úÖ Historical Post (year): 2024-12-09 21:27:14 | BTC | Sentiment: +0.511\n",
      "‚úÖ Historical Post (year): 2025-01-27 06:36:19 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-06-27 15:46:04 | ETH | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-06-05 08:24:16 | BTC | Sentiment: -0.758\n",
      "‚úÖ Historical Post (year): 2025-02-21 13:45:47 | BTC | Sentiment: -0.077\n",
      "‚úÖ Historical Post (year): 2025-08-08 08:44:31 | ETH | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-02-27 15:58:39 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-07-14 03:45:57 | BTC | Sentiment: +0.948\n",
      "‚úÖ Historical Post (year): 2025-07-28 00:16:08 | SOL | Sentiment: +0.052\n",
      "‚úÖ Historical Post (year): 2025-05-09 17:37:46 | BTC | Sentiment: +0.670\n",
      "‚úÖ Historical Post (year): 2024-11-28 12:54:39 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-03-16 16:55:21 | ETH | Sentiment: -0.440\n",
      "‚úÖ Historical Post (year): 2024-11-20 14:27:25 | BTC | Sentiment: -0.273\n",
      "‚úÖ Historical Post (year): 2025-01-24 02:48:08 | BTC | Sentiment: -0.970\n",
      "‚úÖ Historical Post (year): 2025-01-01 02:08:02 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2024-12-12 14:18:17 | DOGE | Sentiment: -0.660\n",
      "‚úÖ Historical Post (year): 2025-03-13 07:32:23 | ETH | Sentiment: +0.625\n",
      "‚úÖ Historical Post (year): 2025-04-19 10:18:58 | BTC | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-06-24 18:09:50 | SOL | Sentiment: -0.402\n",
      "‚úÖ Historical Post (year): 2025-02-25 02:13:55 | ETH | Sentiment: +0.450\n",
      "‚úÖ Historical Post (year): 2025-03-20 04:37:48 | ETH | Sentiment: +0.000\n",
      "‚úÖ Historical Post (year): 2025-05-28 11:09:41 | BTC | Sentiment: -0.296\n",
      "‚úÖ Historical Post (year): 2025-01-03 04:53:33 | BTC | Sentiment: +0.128\n",
      "‚úÖ Historical Post (year): 2025-04-09 05:01:10 | ETH | Sentiment: -0.382\n",
      "\n",
      "--- ‚ö°Ô∏è Running Live Stream Fetch (Every 60s) ---\n",
      "\n",
      "üíæ SAVED 2728 new entries to reddit_crypto_sentiment_analysis.csv\n",
      "\n",
      "--- ‚ö°Ô∏è Running Live Stream Fetch (Every 60s) ---\n",
      "\n",
      "\n",
      "üõë Script interrupted by user (Ctrl+C). Shutting down.\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "# List of time filters to check, ordered from newest to oldest\n",
    "# Note: These are only used for the initial large historical fetch.\n",
    "TIME_FILTERS = [\"day\", \"week\", \"month\", \"year\"]\n",
    "\n",
    "# Define the start date for historical fetch (as before)\n",
    "start_date_str = \"2024-06-15 00:00:00\"\n",
    "start_timestamp = datetime.strptime(start_date_str, \"%Y-%m-%d %H:%M:%S\").timestamp()\n",
    "\n",
    "# Polling intervals in seconds\n",
    "LIVE_STREAM_INTERVAL = 60    # Stream new posts/comments every 3 seconds\n",
    "HISTORICAL_FETCH_INTERVAL = 14400 # Fetch historical data every 2 days (300 seconds)\n",
    "\n",
    "# CSV file path\n",
    "CSV_FILE = \"reddit_crypto_sentiment_analysis.csv\"\n",
    "\n",
    "# --- INITIALIZATION ---\n",
    "\n",
    "# Initialize Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"M9iSExe3kRkwrILVO75-CA\",\n",
    "    client_secret=\"rnuYodBu7llgTAmssHujZVUt37mrAA\",\n",
    "    user_agent=\"crypto-sentiment-app by u/MindlessEssay2919\"\n",
    ")\n",
    "\n",
    "# Define cryptocurrency keywords to track\n",
    "crypto_keywords = {\n",
    "    \"bitcoin\": \"BTC\", \"btc\": \"BTC\",\n",
    "    \"ethereum\": \"ETH\", \"eth\": \"ETH\",\n",
    "    \"cardano\": \"ADA\", \"ada\": \"ADA\",\n",
    "    \"dogecoin\": \"DOGE\", \"doge\": \"DOGE\",\n",
    "    \"solana\": \"SOL\", \"sol\": \"SOL\"\n",
    "}\n",
    "\n",
    "# Initialize sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Initialize a set to prevent processing the same post/comment multiple times\n",
    "processed_ids = set()\n",
    "\n",
    "# Initialize timers\n",
    "last_historical_fetch_time = time.time() - HISTORICAL_FETCH_INTERVAL - 1 # Ensures it runs immediately\n",
    "last_live_stream_time = time.time() - LIVE_STREAM_INTERVAL - 1 # Ensures it runs immediately\n",
    "\n",
    "# Initialize CSV file (only once)\n",
    "df_init = pd.DataFrame(columns=[\n",
    "    \"date\", \"user_id\", \"type\", \"title\", \"cryptocurrency\", \"review\", \"sentiment_score\"\n",
    "])\n",
    "df_init.to_csv(CSV_FILE, index=False)\n",
    "\n",
    "def truncate_to_interval(dt, interval_hours):\n",
    "    \"\"\"\n",
    "     Truncates a datetime object down to the start of the nearest\n",
    "    interval_hours block (e.g., 00:00, 04:00, 08:00 for 4 hours).\n",
    "    This ensures that price and sentiment timestamps align perfectly for joins.\n",
    "    \"\"\"\n",
    "    # Seconds since midnight\n",
    "    total_seconds = (dt - dt.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds()\n",
    "\n",
    "    # Calculate the number of seconds in the interval\n",
    "    interval_seconds = interval_hours * 3600\n",
    "\n",
    "    # Calculate the start of the current interval (integer division)\n",
    "    truncated_seconds = (total_seconds // interval_seconds) * interval_seconds\n",
    "\n",
    "    # Reconstruct the datetime object by adding the truncated seconds to midnight\n",
    "    return dt.replace(hour=0, minute=0, second=0, microsecond=0) + timedelta(seconds=truncated_seconds)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"üîÑ Starting Reddit post & comment sentiment streaming...\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# HELPER FUNCTION FOR DATA PROCESSING\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def process_submission(post, post_type):\n",
    "    \"\"\"Processes a single PRAW submission (post) and its comments, extracts sentiment, and adds to records.\"\"\"\n",
    "    \n",
    "    # Check 1: Has this post been processed already? (Prevents duplicates)\n",
    "    if post.id in processed_ids:\n",
    "        return [] # Return empty if already processed\n",
    "\n",
    "    post_timestamp = post.created_utc\n",
    "    \n",
    "    # Check 2: Ignore posts/comments older than the global start date for the main loop\n",
    "    # This check is primarily for the historical fetch, but good for consistency.\n",
    "    if post_timestamp < start_timestamp:\n",
    "        return []\n",
    "\n",
    "    records = []\n",
    "    \n",
    "    try:\n",
    "        # --- Post Processing ---\n",
    "        title = getattr(post, 'title', '')\n",
    "        review = getattr(post, 'selftext', '') if hasattr(post, 'selftext') else ''\n",
    "        user_id = str(post.author) if post.author else \"Anonymous\"\n",
    "        #date = datetime.utcfromtimestamp(post_timestamp).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        \n",
    "        # --- Inside process_submission function ---\n",
    "\n",
    "        dt_utc = datetime.utcfromtimestamp(post_timestamp)\n",
    "        # Truncate to the nearest 4-hour interval\n",
    "        truncated_dt = truncate_to_interval(dt_utc, interval_hours=4)\n",
    "        date = truncated_dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        # Detect which crypto is mentioned\n",
    "        text_lower = (title + \" \" + review).lower()\n",
    "        found_coin = None\n",
    "        for keyword, symbol in crypto_keywords.items():\n",
    "            if keyword in text_lower:\n",
    "                found_coin = symbol\n",
    "                break\n",
    "        \n",
    "        if not found_coin:\n",
    "            return [] # Skip if no tracked crypto is mentioned\n",
    "\n",
    "        # Sentiment for post\n",
    "        sentiment = analyzer.polarity_scores(title + \" \" + review)[\"compound\"]\n",
    "        records.append([date, user_id, \"post\", title, found_coin, review, sentiment])\n",
    "        processed_ids.add(post.id)\n",
    "        \n",
    "        # --- Comment Processing ---\n",
    "        if post_type == \"historical\":\n",
    "            # For historical, only load a few comments to save time/requests\n",
    "            limit = 10\n",
    "            post.comments.replace_more(limit=0)\n",
    "            comments = post.comments.list()[:limit]\n",
    "        else: # For live stream, load more aggressively\n",
    "            limit = 25\n",
    "            post.comments.replace_more(limit=1)\n",
    "            comments = post.comments.list()[:limit]\n",
    "\n",
    "        for comment in comments:\n",
    "            if isinstance(comment, praw.models.Comment):\n",
    "                comment_text = comment.body\n",
    "                comment_user = str(comment.author) if comment.author else \"Anonymous\"\n",
    "                comment_date = datetime.utcfromtimestamp(comment.created_utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                if not comment_text or comment_text in [\"[deleted]\", \"[removed]\"]:\n",
    "                    continue\n",
    "\n",
    "                comment_lower = comment_text.lower()\n",
    "                comment_coin = found_coin\n",
    "                # Re-check for crypto in the comment itself\n",
    "                for keyword, symbol in crypto_keywords.items():\n",
    "                    if keyword in comment_lower:\n",
    "                        comment_coin = symbol\n",
    "                        break\n",
    "                \n",
    "                # Use a combined ID for comment to track it\n",
    "                comment_id = f\"{post.id}_{comment.id}\"\n",
    "                if comment_id in processed_ids:\n",
    "                    continue\n",
    "                \n",
    "                comment_sent = analyzer.polarity_scores(comment_text)[\"compound\"]\n",
    "                records.append([comment_date, comment_user, \"comment\", title, comment_coin, comment_text, comment_sent])\n",
    "                processed_ids.add(comment_id)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing submission/comment {post.id}: {e}\")\n",
    "        return []\n",
    "\n",
    "    return records\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# DATA FETCHERS\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def fetch_historical_data():\n",
    "    \"\"\"Fetches historical data using the TIME_FILTERS, runs every 5 minutes.\"\"\"\n",
    "    \n",
    "    print(f\"\\n--- ‚è≥ Running Historical Fetch (Every {HISTORICAL_FETCH_INTERVAL}s) ---\")\n",
    "    new_records = []\n",
    "    \n",
    "    for time_filter in TIME_FILTERS:\n",
    "        print(f\"--- Checking Top posts for: {time_filter.upper()} ---\")\n",
    "\n",
    "        # Fetch the top posts for the current time filter\n",
    "        for post in reddit.subreddit(\"CryptoCurrency\").top(time_filter=time_filter, limit=None):\n",
    "            \n",
    "            # Stop if we hit posts older than the start date on the 'year' filter\n",
    "            if time_filter == \"year\" and post.created_utc < start_timestamp:\n",
    "                print(f\"--- Stopping historical fetch: Hit post older than {start_date_str} on 'year' filter. ---\")\n",
    "                return new_records # Return what we have so far\n",
    "\n",
    "            records = process_submission(post, post_type=\"historical\")\n",
    "            if records:\n",
    "                new_records.extend(records)\n",
    "                print(f\"‚úÖ Historical Post ({time_filter}): {datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S')} | {records[0][4]} | Sentiment: {records[0][-1]:+.3f}\")\n",
    "    \n",
    "    return new_records\n",
    "\n",
    "\n",
    "def fetch_live_stream_data():\n",
    "    \"\"\"Fetches the newest data using 'new' or 'stream' approach, runs every 3 seconds.\"\"\"\n",
    "    \n",
    "    print(f\"\\n--- ‚ö°Ô∏è Running Live Stream Fetch (Every {LIVE_STREAM_INTERVAL}s) ---\")\n",
    "    new_records = []\n",
    "    \n",
    "    # Use the 'new' sort for a quick look at the latest posts (limit of 25)\n",
    "    for post in reddit.subreddit(\"CryptoCurrency\").new(limit=25):\n",
    "        records = process_submission(post, post_type=\"live\")\n",
    "        if records:\n",
    "            new_records.extend(records)\n",
    "            print(f\"üî• Live Post: {datetime.utcfromtimestamp(post.created_utc).strftime('%H:%M:%S')} | {records[0][4]} | Sentiment: {records[0][-1]:+.3f}\")\n",
    "            \n",
    "    return new_records\n",
    "\n",
    "def save_records_to_csv(records):\n",
    "    \"\"\"Appends collected records to the CSV file.\"\"\"\n",
    "    if records:\n",
    "        df = pd.DataFrame(records, columns=[\"date\", \"user_id\", \"type\", \"title\", \"cryptocurrency\", \"review\", \"sentiment_score\"])\n",
    "        df.to_csv(CSV_FILE, mode=\"a\", header=False, index=False)\n",
    "        print(f\"\\nüíæ SAVED {len(records)} new entries to {CSV_FILE}\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# MAIN LOOP\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        new_data_to_save = []\n",
    "\n",
    "        # 1. Historical Fetch (Every 5 minutes)\n",
    "        if current_time - last_historical_fetch_time >= HISTORICAL_FETCH_INTERVAL:\n",
    "            historical_records = fetch_historical_data()\n",
    "            new_data_to_save.extend(historical_records)\n",
    "            last_historical_fetch_time = current_time # Reset timer\n",
    "\n",
    "        # 2. Live Stream Fetch (Every 3 seconds)\n",
    "        if current_time - last_live_stream_time >= LIVE_STREAM_INTERVAL:\n",
    "            live_records = fetch_live_stream_data()\n",
    "            new_data_to_save.extend(live_records)\n",
    "            last_live_stream_time = current_time # Reset timer\n",
    "            \n",
    "        # 3. Save any collected data\n",
    "        save_records_to_csv(new_data_to_save)\n",
    "\n",
    "        # Calculate time to sleep until the next live stream fetch\n",
    "        # This keeps the loop running consistently every 3 seconds\n",
    "        sleep_time = LIVE_STREAM_INTERVAL - (time.time() - current_time)\n",
    "        if sleep_time > 0:\n",
    "            time.sleep(sleep_time)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\nüõë Script interrupted by user (Ctrl+C). Shutting down.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n\\nüö® An unexpected error occurred: {e}\")\n",
    "    \n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "665e91d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\yashs\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2d43d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd \n",
    "\n",
    "%cd C:\\Users\\yashs\\source\\repos\\Ripa-Shah\\Sentiment-Analysis\\Analyzing-Social-Sentiment-Data-to-determine-correlation-with-Cryptocurrency-Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ed28b",
   "metadata": {},
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "# List of time filters to check, ordered from newest to oldest\n",
    "TIME_FILTERS = [\"day\", \"week\", \"month\", \"year\"]\n",
    "\n",
    "# Define the start date: June 15, 2025\n",
    "start_date_str = \"2025-06-15 00:00:00\"\n",
    "start_timestamp = datetime.strptime(start_date_str, \"%Y-%m-%d %H:%M:%S\").timestamp()\n",
    "\n",
    "# Polling intervals in seconds\n",
    "LIVE_STREAM_INTERVAL = 172800   # Stream new posts/comments every 2 days\n",
    "HISTORICAL_FETCH_INTERVAL = 172800 # Fetch historical data every 2 days \n",
    "\n",
    "# CSV file path\n",
    "CSV_FILE = \"reddit_crypto_sentiment.csv\"\n",
    "\n",
    "# --- INITIALIZATION ---\n",
    "\n",
    "# Initialize Reddit API (NOTE: Ensure these credentials are valid)\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"M9iSExe3kRkwrILVO75-CA\",\n",
    "    client_secret=\"rnuYodBu7llgTAmssHujZVUt37mrAA\",\n",
    "    user_agent=\"crypto-sentiment-app by u/MindlessEssay2919\"\n",
    ")\n",
    "\n",
    "# Test PRAW Connection\n",
    "try:\n",
    "    test_post = next(reddit.subreddit(\"CryptoCurrency\").hot(limit=1))\n",
    "    print(f\"‚úÖ PRAW Connection successful. Found post: {test_post.title}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå PRAW Connection failed! Error: {e}\")\n",
    "    print(\"Please check your client_id and client_secret.\")\n",
    "    exit() # Stop the script if the connection fails\n",
    "\n",
    "# Define cryptocurrency keywords (simplified for efficiency)\n",
    "crypto_keywords = {\n",
    "    \"bitcoin\": \"BTC\", \"btc\": \"BTC\",\n",
    "    \"ethereum\": \"ETH\", \"eth\": \"ETH\",\n",
    "    \"cardano\": \"ADA\", \"ada\": \"ADA\",\n",
    "    \"dogecoin\": \"DOGE\", \"doge\": \"DOGE\",\n",
    "    \"solana\": \"SOL\", \"sol\": \"SOL\"\n",
    "}\n",
    "\n",
    "# Initialize sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Initialize a set to prevent processing the same post/comment multiple times\n",
    "processed_ids = set()\n",
    "\n",
    "# Initialize timers (set to run immediately on first loop)\n",
    "last_historical_fetch_time = time.time() - HISTORICAL_FETCH_INTERVAL - 1\n",
    "last_live_stream_time = time.time() - LIVE_STREAM_INTERVAL - 1\n",
    "\n",
    "# Initialize CSV file (creates the file with headers)\n",
    "df_init = pd.DataFrame(columns=[\n",
    "    \"date\", \"user_id\", \"type\", \"title\", \"cryptocurrency\", \"review\", \"sentiment_score\"\n",
    "])\n",
    "df_init.to_csv(CSV_FILE, index=False)\n",
    "print(f\"File {CSV_FILE} initialized successfully.\")\n",
    "\n",
    "print(f\"\\nüîÑ Starting Reddit sentiment stream (Tracking since {start_date_str})...\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# HELPER FUNCTIONS\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def process_submission(post, post_type):\n",
    "    \"\"\"Processes a single PRAW submission (post) and its comments.\"\"\"\n",
    "    \n",
    "    # Check 1: Has this post been processed already? \n",
    "    if post.id in processed_ids:\n",
    "        return []\n",
    "\n",
    "    post_timestamp = post.created_utc\n",
    "    \n",
    "    # Check 2: Ignore posts older than the starting date\n",
    "    if post_timestamp < start_timestamp:\n",
    "        return []\n",
    "\n",
    "    records = []\n",
    "    \n",
    "    try:\n",
    "        # --- Post Processing ---\n",
    "        title = getattr(post, 'title', '')\n",
    "        review = getattr(post, 'selftext', '') if hasattr(post, 'selftext') else ''\n",
    "        user_id = str(post.author) if post.author else \"Anonymous\"\n",
    "        date = datetime.utcfromtimestamp(post_timestamp).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        # Detect crypto (text is already lowercased for checking efficiency)\n",
    "        text_lower = (title + \" \" + review).lower()\n",
    "        found_coin = None\n",
    "        for keyword, symbol in crypto_keywords.items():\n",
    "            if keyword in text_lower:\n",
    "                found_coin = symbol\n",
    "                break\n",
    "        \n",
    "        if not found_coin:\n",
    "            return []\n",
    "\n",
    "        # Sentiment for post\n",
    "        sentiment = analyzer.polarity_scores(title + \" \" + review)[\"compound\"]\n",
    "        records.append([date, user_id, \"post\", title, found_coin, review, sentiment])\n",
    "        processed_ids.add(post.id)\n",
    "        \n",
    "        # --- Comment Processing ---\n",
    "        limit = 10 if post_type == \"historical\" else 25\n",
    "        \n",
    "        # This resolves MoreComments objects to actual comments\n",
    "        post.comments.replace_more(limit=0 if post_type == \"historical\" else 1)\n",
    "        comments = post.comments.list()[:limit]\n",
    "\n",
    "        for comment in comments:\n",
    "            if isinstance(comment, praw.models.Comment):\n",
    "                comment_text = comment.body\n",
    "                comment_user = str(comment.author) if comment.author else \"Anonymous\"\n",
    "                \n",
    "                if not comment_text or comment_text in [\"[deleted]\", \"[removed]\"]:\n",
    "                    continue\n",
    "\n",
    "                comment_id = f\"{post.id}_{comment.id}\"\n",
    "                if comment_id in processed_ids:\n",
    "                    continue\n",
    "                \n",
    "                comment_date = datetime.utcfromtimestamp(comment.created_utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                comment_lower = comment_text.lower()\n",
    "                comment_coin = found_coin # Inherit post coin initially\n",
    "\n",
    "                # Re-check for crypto in the comment itself\n",
    "                for keyword, symbol in crypto_keywords.items():\n",
    "                    if keyword in comment_lower:\n",
    "                        comment_coin = symbol\n",
    "                        break\n",
    "                \n",
    "                comment_sent = analyzer.polarity_scores(comment_text)[\"compound\"]\n",
    "                records.append([comment_date, comment_user, \"comment\", title, comment_coin, comment_text, comment_sent])\n",
    "                processed_ids.add(comment_id)\n",
    "                \n",
    "    except Exception as e:\n",
    "        # Catch errors like deleted posts/authors/comments\n",
    "        # print(f\"Error processing submission/comment {post.id}: {e}\") \n",
    "        return []\n",
    "\n",
    "    return records\n",
    "\n",
    "\n",
    "def fetch_historical_data():\n",
    "    \"\"\"Fetches historical data using the TIME_FILTERS, runs every 5 minutes.\"\"\"\n",
    "    \n",
    "    print(f\"\\n--- ‚è≥ Running Historical Fetch (Top posts since {start_date_str}) ---\")\n",
    "    new_records = []\n",
    "    \n",
    "    for time_filter in TIME_FILTERS:\n",
    "        # Fetch the top posts for the current time filter (PRAW's limit is ~1000)\n",
    "        for post in reddit.subreddit(\"CryptoCurrency\").top(time_filter=time_filter, limit=None):\n",
    "            \n",
    "            # This handles stopping the deep search once we hit very old, irrelevant content\n",
    "            if time_filter == \"year\" and post.created_utc < start_timestamp:\n",
    "                print(f\"--- Stopping historical fetch: Hit content older than {start_date_str} ---\")\n",
    "                return new_records \n",
    "\n",
    "            records = process_submission(post, post_type=\"historical\")\n",
    "            if records:\n",
    "                new_records.extend(records)\n",
    "                print(f\"‚úÖ Historical Post ({time_filter}): {datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S')} | {records[0][4]} | Sentiment: {records[0][-1]:+.3f}\")\n",
    "    \n",
    "    return new_records\n",
    "\n",
    "\n",
    "def fetch_live_stream_data():\n",
    "    \"\"\"Fetches the newest data using 'new' sort, runs every 3 seconds.\"\"\"\n",
    "    \n",
    "    print(f\"\\n--- ‚ö°Ô∏è Running Live Stream Fetch (Every {LIVE_STREAM_INTERVAL}s) ---\")\n",
    "    new_records = []\n",
    "    \n",
    "    # Use the 'new' sort for a quick look at the latest posts (limit of 25)\n",
    "    for post in reddit.subreddit(\"CryptoCurrency\").new(limit=25):\n",
    "        records = process_submission(post, post_type=\"live\")\n",
    "        if records:\n",
    "            new_records.extend(records)\n",
    "            print(f\"üî• Live Post: {datetime.utcfromtimestamp(post.created_utc).strftime('%H:%M:%S')} | {records[0][4]} | Sentiment: {records[0][-1]:+.3f}\")\n",
    "            \n",
    "    return new_records\n",
    "\n",
    "\n",
    "def save_records_to_csv(records):\n",
    "    \"\"\"Appends collected records to the CSV file.\"\"\"\n",
    "    if records:\n",
    "        df = pd.DataFrame(records, columns=[\"date\", \"user_id\", \"type\", \"title\", \"cryptocurrency\", \"review\", \"sentiment_score\"])\n",
    "        # Append data to the CSV without writing the header again\n",
    "        df.to_csv(CSV_FILE, mode=\"a\", header=False, index=False)\n",
    "        print(f\"\\nüíæ SAVED {len(records)} new entries to {CSV_FILE}\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# MAIN LOOP\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        current_time = time.time()\n",
    "        new_data_to_save = []\n",
    "\n",
    "        # 1. Historical Fetch (Every 5 minutes)\n",
    "        if current_time - last_historical_fetch_time >= HISTORICAL_FETCH_INTERVAL:\n",
    "            historical_records = fetch_historical_data()\n",
    "            new_data_to_save.extend(historical_records)\n",
    "            last_historical_fetch_time = current_time # Reset timer\n",
    "\n",
    "        # 2. Live Stream Fetch (Every 3 seconds)\n",
    "        if current_time - last_live_stream_time >= LIVE_STREAM_INTERVAL:\n",
    "            live_records = fetch_live_stream_data()\n",
    "            new_data_to_save.extend(live_records)\n",
    "            last_live_stream_time = current_time # Reset timer\n",
    "            \n",
    "        # 3. Save any collected data\n",
    "        if new_data_to_save:\n",
    "            save_records_to_csv(new_data_to_save)\n",
    "        \n",
    "        # Calculate time to sleep to maintain the 3-second live stream interval\n",
    "        time_spent = time.time() - current_time\n",
    "        sleep_time = max(0, LIVE_STREAM_INTERVAL - time_spent)\n",
    "        \n",
    "        if sleep_time > 0:\n",
    "            time.sleep(sleep_time)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\nüõë Script interrupted by user (Ctrl+C). Shutting down.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n\\nüö® An unexpected error occurred: {e}\")\n",
    "    \n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d00ef576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yfinance in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (0.2.66)\n",
      "Requirement already satisfied: pandas in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from yfinance) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from yfinance) (2.32.5)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from yfinance) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from yfinance) (4.4.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from yfinance) (2025.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from yfinance) (3.18.3)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from yfinance) (4.13.5)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from yfinance) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from yfinance) (6.33.0)\n",
      "Requirement already satisfied: websockets>=13.0 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from yfinance) (15.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from curl_cffi>=0.7->yfinance) (2025.8.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests>=2.31->yfinance) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yashs\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests>=2.31->yfinance) (2.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eede0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\2972712628.py:19: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df_historical_wide = yf.download(\n",
      "\n",
      "5 Failed downloads:\n",
      "['ADA-USD', 'ETH-USD', 'SOL-USD', 'DOGE-USD', 'BTC-USD']: ValueError(\"Unable to parse input dt 1718434800.0 of type <class 'float'>\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fetching Historical Data from 1718434800.0 at 5d intervals ---\n",
      "\n",
      "‚úÖ Historical data successfully retrieved and saved to crypto_prices.csv\n",
      "Total historical records: 0\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "# --- Configuration ---\n",
    "\n",
    "start_date_str = \"2024-06-15 00:00:00\"\n",
    "HISTORICAL_START_DATE = datetime.strptime(start_date_str, \"%Y-%m-%d %H:%M:%S\").timestamp()\n",
    "\n",
    "TICKERS = [\"BTC-USD\", \"ETH-USD\", \"ADA-USD\", \"DOGE-USD\", \"SOL-USD\"]\n",
    "#HISTORICAL_START_DATE = \"2024-06-15\"\n",
    "HISTORICAL_INTERVAL = \"5d\"  # 5-minute intervals\n",
    "CSV_FILE_HISTORICAL = \"crypto_prices.csv\"\n",
    "\n",
    "print(f\"\\n--- Fetching Historical Data from {HISTORICAL_START_DATE} at {HISTORICAL_INTERVAL} intervals ---\")\n",
    "\n",
    "try:\n",
    "    # Use start= and interval= for historical data\n",
    "    df_historical_wide = yf.download(\n",
    "        tickers=TICKERS,\n",
    "        start=HISTORICAL_START_DATE,\n",
    "        interval=HISTORICAL_INTERVAL,\n",
    "        progress=False\n",
    "    )[\"Close\"]\n",
    "\n",
    "    # Convert the wide format DataFrame to a long (melted) format\n",
    "    # This aligns with the structure of your CSV output (timestamp, symbol, price)\n",
    "    df_historical_wide.index.name = \"timestamp\"\n",
    "    \n",
    "    df_historical_long = df_historical_wide.reset_index().melt(\n",
    "        id_vars='timestamp',\n",
    "        value_vars=TICKERS,\n",
    "        var_name='symbol',\n",
    "        value_name='price'\n",
    "    ).dropna() # Remove rows where price data might be missing\n",
    "\n",
    "    # Save to CSV\n",
    "    df_historical_long.to_csv(CSV_FILE_HISTORICAL, index=False)\n",
    "\n",
    "    print(f\"\\n‚úÖ Historical data successfully retrieved and saved to {CSV_FILE_HISTORICAL}\")\n",
    "    print(f\"Total historical records: {len(df_historical_long):,}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error retrieving historical data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a495d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2852824729.py, line 31)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mstart_date_str = datetime.\u001b[39m\n                              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Configuration ---\n",
    "TICKERS = [\"BTC-USD\", \"ETH-USD\", \"ADA-USD\", \"DOGE-USD\", \"SOL-USD\"]\n",
    "CSV_FILE_LIVE = \"crypto_prices.csv\"\n",
    "LIVE_UPDATE_INTERVAL = \"5\"  # Seconds\n",
    "\n",
    "# Initialize CSV file with headers (only once)\n",
    "df_init = pd.DataFrame(columns=[\"timestamp\", \"symbol\", \"price\"])\n",
    "df_init.to_csv(CSV_FILE_LIVE, index=False)\n",
    "\n",
    "print(f\"Starting live crypto price retrieval every {LIVE_UPDATE_INTERVAL} seconds...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Get latest 1-minute bar data. '1m' is the smallest interval yfinance supports.\n",
    "        # We request the last 5 minutes of data ('5m') to ensure we catch the latest bar.\n",
    "        data = yf.download(\n",
    "            tickers=TICKERS,\n",
    "            period=\"1d\",\n",
    "            interval=\"5d\",\n",
    "            progress=False\n",
    "        )[\"Close\"].tail(1)\n",
    "\n",
    "        # Check if data was successfully retrieved (Yahoo sometimes returns NaN/empty)\n",
    "        if not data.empty and not data.iloc[0].isnull().all():\n",
    "            #datetm = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            start_date_str = datetime.now()\n",
    "            #start_timestamp = datetime.strptime(start_date_str, \"%Y-%m-%d %H:%M:%S\").timestamp()\n",
    "\n",
    "            #start_timestamp = datetime.strptime(start_date_str, \"%Y-%m-%d %H:%M:%S\").timestamp()\n",
    "            start_timestamp = datetime.utcfromtimestamp(start_date_str).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            #timestamp = datetime.now().strptime(datetm,\"%Y-%m-%d %H:%M:%S\").timestamp()\n",
    "            records = []\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "            # Iterate through available data (only tickers present in data)\n",
    "            for symbol in TICKERS:\n",
    "                try:\n",
    "                    price = data[symbol].values[0]\n",
    "                    records.append([start_timestamp, symbol, price])\n",
    "                    print(f\"{start_timestamp} | {symbol} | ${price:.4f}\")\n",
    "                except IndexError:\n",
    "                    pass\n",
    "\n",
    "            # Append to CSV file\n",
    "            df = pd.DataFrame(records, columns=[\"timestamp\", \"symbol\", \"price\"])\n",
    "            df.to_csv(CSV_FILE_LIVE, mode=\"a\", header=False, index=False)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | No new price data retrieved.\")\n",
    "\n",
    "        # Wait for 3 seconds before the next update\n",
    "        time.sleep(int(LIVE_UPDATE_INTERVAL))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nLive streaming stopped by user.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd541060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Fetching Historical Data from 2024-06-15 at 4h intervals ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:46: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df_historical_wide = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Historical data successfully retrieved and saved to crypto_prices.csv\n",
      "Total historical records: 15,620\n",
      "\n",
      "--- 2. Starting Live Crypto Price Retrieval every 5 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91943.6328\n",
      "2025-11-17 12:00:00 | ETH-USD | $3014.8193\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91943.6328\n",
      "2025-11-17 12:00:00 | ETH-USD | $3014.8193\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91943.6328\n",
      "2025-11-17 12:00:00 | ETH-USD | $3014.8193\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91943.6328\n",
      "2025-11-17 12:00:00 | ETH-USD | $3014.8193\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91943.6328\n",
      "2025-11-17 12:00:00 | ETH-USD | $3014.8193\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91943.6328\n",
      "2025-11-17 12:00:00 | ETH-USD | $3014.8193\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91943.6328\n",
      "2025-11-17 12:00:00 | ETH-USD | $3014.8193\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91943.6328\n",
      "2025-11-17 12:00:00 | ETH-USD | $3014.8193\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91943.6328\n",
      "2025-11-17 12:00:00 | ETH-USD | $3014.8193\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91943.6328\n",
      "2025-11-17 12:00:00 | ETH-USD | $3014.8193\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91943.6328\n",
      "2025-11-17 12:00:00 | ETH-USD | $3014.8193\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91912.0859\n",
      "2025-11-17 12:00:00 | ETH-USD | $3013.3000\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91912.0859\n",
      "2025-11-17 12:00:00 | ETH-USD | $3013.3000\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91912.0859\n",
      "2025-11-17 12:00:00 | ETH-USD | $3013.3000\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91912.0859\n",
      "2025-11-17 12:00:00 | ETH-USD | $3013.3000\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91912.0859\n",
      "2025-11-17 12:00:00 | ETH-USD | $3013.3000\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91912.0859\n",
      "2025-11-17 12:00:00 | ETH-USD | $3013.3000\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91912.0859\n",
      "2025-11-17 12:00:00 | ETH-USD | $3013.3000\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91912.0859\n",
      "2025-11-17 12:00:00 | ETH-USD | $3013.3000\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91912.0859\n",
      "2025-11-17 12:00:00 | ETH-USD | $3013.3000\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | BTC-USD | $91912.0859\n",
      "2025-11-17 12:00:00 | ETH-USD | $3013.3000\n",
      "2025-11-17 12:00:00 | ADA-USD | $0.4632\n",
      "2025-11-17 12:00:00 | DOGE-USD | $0.1522\n",
      "2025-11-17 12:00:00 | SOL-USD | $131.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_11732\\1254874932.py:90: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 12:00:00 | ADA-USD | $0.4631\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'crypto_prices.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 127\u001b[39m\n\u001b[32m    125\u001b[39m     df_live = pd.DataFrame(records, columns=[\u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msymbol\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprice\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    126\u001b[39m     \u001b[38;5;66;03m# Use mode='a' to append, and header=False to avoid writing the header again\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     \u001b[43mdf_live\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCSV_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ma\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    129\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | No new price data retrieved/data was NaN.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'crypto_prices.csv'"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta # <- timedelta is REQUIRED for the function\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "TICKERS = [\"BTC-USD\", \"ETH-USD\", \"ADA-USD\", \"DOGE-USD\", \"SOL-USD\"]\n",
    "HISTORICAL_START_DATE = \"2024-06-15\"\n",
    "# NOTE: The Reddit script must use this same interval (4 hours = 4)\n",
    "HISTORICAL_INTERVAL = \"4h\" \n",
    "CSV_FILE = \"crypto_prices.csv\"\n",
    "LIVE_UPDATE_INTERVAL = 5  # Use an integer/float for time.sleep()\n",
    "LIVE_FETCH_INTERVAL = \"1m\" \n",
    "file_exists = os.path.exists(CSV_FILE)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# HELPER FUNCTION FOR TIME ALIGNMENT (MOVED HERE TO PREVENT NameError)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def truncate_to_interval(dt, interval_hours):\n",
    "    \"\"\"\n",
    "    Truncates a datetime object down to the start of the nearest\n",
    "    interval_hours block (e.g., 00:00, 04:00, 08:00 for 4 hours).\n",
    "    This ensures that price and sentiment timestamps align perfectly for joins.\n",
    "    \"\"\"\n",
    "    # Seconds since midnight\n",
    "    total_seconds = (dt - dt.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds()\n",
    "    \n",
    "    # Calculate the number of seconds in the interval\n",
    "    interval_seconds = interval_hours * 3600\n",
    "    \n",
    "    # Calculate the start of the current interval (integer division)\n",
    "    truncated_seconds = (total_seconds // interval_seconds) * interval_seconds\n",
    "    \n",
    "    # Reconstruct the datetime object by adding the truncated seconds to midnight\n",
    "    return dt.replace(hour=0, minute=0, second=0, microsecond=0) + timedelta(seconds=truncated_seconds)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. Historical Data Retrieval and CSV Initialization\n",
    "# ----------------------------------------------------------------------\n",
    "print(f\"--- 1. Fetching Historical Data from {HISTORICAL_START_DATE} at {HISTORICAL_INTERVAL} intervals ---\")\n",
    "\n",
    "try:\n",
    "    # Fetch historical data\n",
    "    df_historical_wide = yf.download(\n",
    "        tickers=TICKERS,\n",
    "        start=HISTORICAL_START_DATE,\n",
    "        interval=HISTORICAL_INTERVAL,\n",
    "        progress=False\n",
    "    )[\"Close\"]\n",
    "\n",
    "    # Convert to long format\n",
    "    df_historical_wide.index.name = \"timestamp\"\n",
    "    df_historical_long = df_historical_wide.reset_index().melt(\n",
    "        id_vars='timestamp',\n",
    "        value_vars=TICKERS,\n",
    "        var_name='symbol',\n",
    "        value_name='price'\n",
    "    ).dropna() # Remove rows where price data might be missing\n",
    "\n",
    "    # Historical data timestamps are already truncated to the start of the interval \n",
    "    # by yfinance. We only need to format them as a string.\n",
    "    df_historical_long['timestamp'] = df_historical_long['timestamp'].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Save to CSV\n",
    "    if not file_exists:\n",
    "        df_historical_long.to_csv(CSV_FILE, index=False, mode='w')\n",
    "    else:\n",
    "        df_historical_long.to_csv(CSV_FILE, index=False, mode='a', header=False) # Use header=False when appending\n",
    "\n",
    "    print(f\"\\n‚úÖ Historical data successfully retrieved and saved to {CSV_FILE}\")\n",
    "    print(f\"Total historical records: {len(df_historical_long):,}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error retrieving historical data: {e}\")\n",
    "    # If historical fetch fails, still initialize the file with only the header\n",
    "    pd.DataFrame(columns=[\"timestamp\", \"symbol\", \"price\"]).to_csv(CSV_FILE, index=False, mode='w')\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. Live Data Streaming and Appending\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "print(f\"\\n--- 2. Starting Live Crypto Price Retrieval every {LIVE_UPDATE_INTERVAL} seconds ---\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Get the latest data point\n",
    "        data = yf.download(\n",
    "            tickers=TICKERS,\n",
    "            period=\"1d\",\n",
    "            interval=LIVE_FETCH_INTERVAL,\n",
    "            progress=False\n",
    "        )[\"Close\"].tail(1) # Take only the last row\n",
    "\n",
    "        # Check if data was successfully retrieved\n",
    "        if not data.empty and not data.iloc[0].isnull().all():\n",
    "            \n",
    "            current_dt = datetime.now()\n",
    "            \n",
    "            # --- APPLY TIME TRUNCATION HERE ---\n",
    "            # Truncate the live price timestamp to match the 4-hour bar interval\n",
    "            truncated_dt = truncate_to_interval(current_dt, interval_hours=4)\n",
    "            timestamp = truncated_dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            # -----------------------------------\n",
    "            \n",
    "            records = []\n",
    "\n",
    "            # Iterate through available data\n",
    "            for symbol in TICKERS:\n",
    "                try:\n",
    "                    price = data[symbol].values[0] \n",
    "                    \n",
    "                    if not pd.isna(price): # Ensure price is not NaN\n",
    "                        records.append([timestamp, symbol, price])\n",
    "                        print(f\"{timestamp} | {symbol} | ${price:.4f}\")\n",
    "                        \n",
    "                except Exception:\n",
    "                    # Handles cases where a symbol might be missing from the DataFrame\n",
    "                    pass\n",
    "\n",
    "            # Append the new live data to the CSV file\n",
    "            if records:\n",
    "                df_live = pd.DataFrame(records, columns=[\"timestamp\", \"symbol\", \"price\"])\n",
    "                # Use mode='a' to append, and header=False to avoid writing the header again\n",
    "                df_live.to_csv(CSV_FILE, mode=\"a\", header=False, index=False)\n",
    "            else:\n",
    "                print(f\"{timestamp} | No new price data retrieved/data was NaN.\")\n",
    "\n",
    "            # Wait for the configured interval\n",
    "            time.sleep(LIVE_UPDATE_INTERVAL)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nLive streaming stopped by user.\")\n",
    "except TypeError as e:\n",
    "    print(f\"\\nError: {e}. Check that LIVE_UPDATE_INTERVAL is a number (integer/float).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
